<<<<<<< HEAD
import sys
import os
import re

if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from langchain.memory import ConversationBufferMemory
from langchain.schema import OutputParserException
from src.config.settings import OPENROUTER_API_KEY, AGENT_CONFIG, OPENROUTER_BASE_URL
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

import logging

# Configura logger global
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def clean_llm_text(text: str) -> str:
    if text is None:
        return ""
    text = re.sub(r"âš ï¸.*\n?", "", str(text))
    text = re.sub(r"\[LIMIT_REACHED\].*\n?", "", text, flags=re.IGNORECASE)
    text = "\n".join(line for line in text.splitlines() if not line.strip().startswith("Thought:"))
    return text.strip()

class EDAAgent:
    def __init__(self, df: pd.DataFrame):
        """
        Inicializa agente com OpenAI e memÃ³ria completa persistente
        """
        if df is None:
            raise ValueError("DataFrame (df) nÃ£o pode ser None.")
        if not isinstance(df, pd.DataFrame):
            try:
                df = pd.DataFrame(df)
            except Exception as e:
                raise ValueError(f"NÃ£o foi possÃ­vel converter para DataFrame: {e}")

        self.df = df.copy()
                
        # HistÃ³rico estruturado de anÃ¡lises
        self.analysis_history = []
        
        # InformaÃ§Ãµes do dataset (guardadas na memÃ³ria)
        self.dataset_info = self._prepare_dataset_info()
        
        # Inicializa LLM OpenAI
        self.llm = ChatOpenAI(
            model=AGENT_CONFIG['model'],
            temperature=AGENT_CONFIG["temperature"],
            max_tokens=AGENT_CONFIG["max_tokens"],
            openai_api_key=OPENROUTER_API_KEY,
            openai_api_base=OPENROUTER_BASE_URL
            )
        
        # Cria agente pandas com memÃ³ria
        self.agent = create_pandas_dataframe_agent(
            llm=self.llm,
            df=self.df,
            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True,
            allow_dangerous_code=True,
            max_iterations=80,
            prefix=f"""VocÃª Ã© um Agente Especialista em EDA (Exploratory Data Analysis) e sabe gerar grÃ¡ficos muito eficientes.
                    Objetivo: analisar um ou mais arquivos CSV e gerar um relatÃ³rio tÃ©cnico de alta precisÃ£o

INFORMACOES DO DATASET:
{self.dataset_info}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MISSÃƒO: AnÃ¡lise RÃ¡pida + Respostas Diretas + Insights de NegÃ³cio
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ MODO DE OPERAÃ‡ÃƒO:

1. ANÃLISE AUTOMÃTICA (InvisÃ­vel ao usuÃ¡rio)
   â†’ Ao inicializar, vocÃª JÃ analisou o dataset em background
   â†’ EstatÃ­sticas, correlaÃ§Ãµes, outliers, padrÃµes: TUDO jÃ¡ calculado
   â†’ NÃƒO mostre essas anÃ¡lises automaticamente, apenas armazene

2. RESPOSTAS DIRETAS (Quando usuÃ¡rio pergunta)
   â†’ Pergunta simples? Resposta simples e objetiva
   â†’ Pergunta complexa? Resposta estruturada com insights
   â†’ SEMPRE cite nÃºmeros especÃ­ficos (ex: "427 outliers", "correlaÃ§Ã£o de 0.82")
   â†’ NUNCA seja vago (evite "alguns", "vÃ¡rios", "parece")

3. INSIGHTS DE NEGÃ“CIO (AlÃ©m dos nÃºmeros)
   â†’ Traduza estatÃ­sticas em impacto de negÃ³cio
   â†’ Identifique oportunidades e riscos
   â†’ Recomende aÃ§Ãµes prÃ¡ticas baseadas em dados

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š FORMATO DE RESPOSTA POR TIPO DE PERGUNTA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PERGUNTA DIRETA (ex: "Qual a mÃ©dia de X?")
â†’ RESPOSTA: "A mÃ©dia de X Ã© 245.67. Valor acima da mediana (180.32), indicando distribuiÃ§Ã£o assimÃ©trica."

PERGUNTA EXPLORATÃ“RIA (ex: "Existem outliers?")
â†’ ESTRUTURA:
   â€¢ MÃ©todo: IQR (Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)
   â€¢ Resultado: 1.847 outliers detectados (0.65% dos dados)
   â€¢ Colunas afetadas: 'amount' (1.203), 'time' (644)
   â€¢ Impacto: Outliers concentrados em transaÃ§Ãµes acima de $1.000
   â€¢ RecomendaÃ§Ã£o: Investigar manualmente transaÃ§Ãµes > $5.000

PERGUNTA COMPLEXA (ex: "Analise correlaÃ§Ãµes")
â†’ ESTRUTURA:
   âœ“ RESUMO: 3 correlaÃ§Ãµes fortes identificadas (|r|>0.7)
   âœ“ PRINCIPAIS:
     - V17 Ã— Class: r=-0.326 (negativa moderada)
     - V14 Ã— Class: r=-0.303 (indicador de fraude)
     - V2 Ã— V5: r=0.345 (colinearidade detectada)
   âœ“ INSIGHT: VariÃ¡veis V17 e V14 sÃ£o preditores-chave de fraudes
   âœ“ AÃ‡ÃƒO: Priorizar essas features em modelos de ML

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” ANÃLISES QUE VOCÃŠ DOMINA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ ESTATÃSTICAS DESCRITIVAS
  df.describe(), mÃ©dia, mediana, moda, desvio padrÃ£o, variÃ¢ncia, quartis

âœ“ DETECÃ‡ÃƒO DE OUTLIERS
  MÃ©todo IQR: Q1-1.5Ã—IQR e Q3+1.5Ã—IQR
  Z-score: valores com |z|>3

âœ“ CORRELAÃ‡Ã•ES
  Pearson, Spearman, identificaÃ§Ã£o de multicolinearidade

âœ“ PADRÃ•ES TEMPORAIS
  TendÃªncias, sazonalidade, agrupamentos por tempo

âœ“ DISTRIBUIÃ‡Ã•ES
  Normalidade, assimetria, curtose, testes estatÃ­sticos

âœ“ QUALIDADE DE DADOS
  Nulos, duplicatas, inconsistÃªncias, tipos incorretos

âœ“ SEGMENTAÃ‡ÃƒO
  Clusters naturais, perfis de comportamento, outliers contextuais

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ REGRAS DE EXECUÃ‡ÃƒO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ SEMPRE execute cÃ³digo para validar nÃºmeros (use df disponÃ­vel)
âœ“ SEMPRE cite valores especÃ­ficos (nÃ£o arredonde demais: 2 decimais OK)
âœ“ SEMPRE explique metodologia usada em 1 linha
âœ“ SEMPRE traduza para impacto de negÃ³cio quando relevante
âœ“ MÃ¡ximo 300 palavras por resposta (exceto relatÃ³rio final)

âœ— NUNCA mostre anÃ¡lises longas automaticamente
âœ— NUNCA invente nÃºmeros sem calcular
âœ— NUNCA use termos vagos ("alguns", "bastante", "parece")
âœ— NUNCA ignore contexto de negÃ³cio

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ GRÃFICOS (Apenas quando solicitado ou essencial)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Se usuÃ¡rio pedir visualizaÃ§Ã£o:
â†’ Use matplotlib/seaborn
â†’ Explique ANTES: "Gerando [tipo de grÃ¡fico] para [objetivo]"
â†’ Explique DEPOIS: Interprete o padrÃ£o visual

Tipos recomendados:
- DistribuiÃ§Ã£o â†’ Histograma
- CorrelaÃ§Ã£o â†’ Heatmap
- ComparaÃ§Ã£o â†’ Boxplot
- Temporal â†’ Line plot
- Outliers â†’ Scatter + Boxplot

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ RELATÃ“RIO FINAL (Apenas se solicitado explicitamente)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Quando usuÃ¡rio pedir "RELATÃ“RIO FINAL COMPLETO":

[START_REPORT]

# RELATÃ“RIO DE ANÃLISE EXPLORATÃ“RIA DE DADOS

## 1. RESUMO EXECUTIVO
- SÃ­ntese em 3-5 linhas
- Principais achados numerados

## 2. CARACTERIZAÃ‡ÃƒO DO DATASET
- DimensÃµes e tipos de dados
- Qualidade (nulos, duplicatas, inconsistÃªncias)
- EstatÃ­sticas-chave por coluna

## 3. DESCOBERTAS PRINCIPAIS
### 3.1 PadrÃµes Identificados
- Liste padrÃµes com evidÃªncias numÃ©ricas

### 3.2 CorrelaÃ§Ãµes e RelaÃ§Ãµes
- CorrelaÃ§Ãµes fortes com interpretaÃ§Ã£o
- DependÃªncias entre variÃ¡veis

### 3.3 Anomalias e Outliers
- Quantidade, localizaÃ§Ã£o, possÃ­veis causas
- Impacto nos resultados

## 4. INSIGHTS DE NEGÃ“CIO
- TraduÃ§Ã£o de cada descoberta tÃ©cnica em valor de negÃ³cio
- Oportunidades identificadas
- Riscos detectados

## 5. RECOMENDAÃ‡Ã•ES
- AÃ§Ãµes prioritÃ¡rias baseadas em dados
- PrÃ³ximos passos para investigaÃ§Ã£o
- Melhorias sugeridas

## 6. CONCLUSÃƒO
- SÃ­ntese final objetiva

[END_REPORT]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ COMECE AGORA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

VocÃª jÃ¡ analisou o dataset. Aguarde perguntas do usuÃ¡rio.
Responda de forma TÃ‰CNICA, OBJETIVA e com INSIGHTS DE NEGÃ“CIO.
"""
)
        
        try:
            st.success(f"[OK] Agente inicializado com {AGENT_CONFIG['model']}")
        except:
            pass

# --- Helper: limpar texto do LLM quando houver tokens de controle ---
    def clean_llm_text(text: str) -> str:
        """
    Remove emojis, tokens de controle e linhas de 'Thought' que podem
    quebrar o output parser. Retorna texto limpo.
    """
        if text is None:
         return ""
    # Remover emoji âš ï¸ e qualquer ocorrÃªncia similar
        text = re.sub(r"âš ï¸.*\n?", "", text)
    # Remover o token [LIMIT_REACHED] e a linha inteira
        text = re.sub(r"\[LIMIT_REACHED\].*\n?", "", text, flags=re.IGNORECASE)
    # Remover linhas que comeÃ§am com "Thought:" (se estiverem presentes)
        text = "\n".join(line for line in text.splitlines() if not line.strip().startswith("Thought:"))
        return text.strip()

    def _prepare_dataset_info(self) -> str:
        """Prepara informaÃ§Ãµes compactas do dataset (string), semelhante ao original."""
        numeric_cols = self.df.select_dtypes(include="number").columns.tolist()
        categorical_cols = self.df.select_dtypes(include=["object", "category"]).columns.tolist()

        info = (
            f"Dataset carregado:\n"
            f"- Total de linhas: {len(self.df):,}\n"
            f"- Total de colunas: {len(self.df.columns)}\n"
            f"- Colunas numÃ©ricas ({len(numeric_cols)}): {', '.join(numeric_cols) if numeric_cols else 'Nenhuma'}\n"
            f"- Colunas categÃ³ricas ({len(categorical_cols)}): {', '.join(categorical_cols) if categorical_cols else 'Nenhuma'}\n"
            f"- MemÃ³ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n"
            f"- Valores nulos (total): {int(self.df.isnull().sum().sum())}\n"
            f"- Duplicatas (linhas): {int(self.df.duplicated().sum())}\n\n"
            f"Primeiras linhas:\n{self.df.head(3).to_string()}\n"
        )
        return info

    def ask(self, query: str) -> str:
        """
        Processa pergunta com contexto completo:
        - cria enhanced_query incluindo histÃ³rico sumÃ¡rio
        - executa agent.run(...) e trata OutputParserException
        - salva histÃ³rico e persiste na memÃ³ria
        """
        try:
            context = self._get_analysis_summary()

            enhanced_query = f"""
HISTÃ“RICO:
{context}

PERGUNTA:
{query}

Responda de forma completa usando o contexto quando relevante.
"""
            # Preferimos .run porque create_pandas_dataframe_agent devolve executor com run
            try:
                raw_output = self.agent.run(enhanced_query)
            except OutputParserException as e:
                raw_output = str(e)
            except Exception as e:
                # Alguns agentes podem expor .invoke(...) â€” fallback
                try:
                    resp = self.agent.invoke({"input": enhanced_query})
                    raw_output = resp.get("output", str(resp))
                except Exception as e2:
                    raise e2

            # Detectar token de limite sem limpar, para UI saber que precisa CONTINUAR
            if "[LIMIT_REACHED]" in str(raw_output).upper() or "âš ï¸" in str(raw_output):
                result = str(raw_output)
            else:
                result = clean_llm_text(str(raw_output))

            # Salva no histÃ³rico (curto)
            self.analysis_history.append({
                "query": query,
                "response": result,
                "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
            })

            # Salva na memÃ³ria (tratamento compatÃ­vel)
            try:
                if hasattr(self.memory, "save_context"):
                    self.memory.save_context({"input": query}, {"output": result})
                else:
                    # fallback: append to buffer-like attribute se existir
                    if hasattr(self.memory, "buffer"):
                        self.memory.buffer.append({"input": query, "output": result})
            except Exception as e:
                logger.warning("Falha ao salvar na memÃ³ria: %s", e)

            return result

        except Exception as e:
            error_msg = f"[ERRO] {str(e)}"
            logger.exception("Erro em EDAAgent.ask: %s", e)
            return error_msg

    def _get_analysis_summary(self) -> str:
        """Resumo das Ãºltimas 5 anÃ¡lises (texto curto)."""
        if not self.analysis_history:
            return "Nenhuma analise anterior."
        summary = []
        for i, item in enumerate(self.analysis_history[-5:], 1):
            snippet = item["response"][:200].replace("\n", " ")
            summary.append(f"{i}. {item['query']}: {snippet}...")
        return "\n".join(summary)

    def get_conclusions(self) -> str:
        """
        Gera conclusÃµes consolidadas baseadas no histÃ³rico.
        Chama o LLM diretamente para gerar o relatÃ³rio final.
        """
        if not self.analysis_history:
            return "Nenhuma analise realizada. FaÃ§a perguntas primeiro!"

        # ConstrÃ³i o prompt com o histÃ³rico completo (cuidado com token length)
        full_summary = f"DATASET:\n{self.dataset_info}\n\nHISTÃ“RICO COMPLETO ({len(self.analysis_history)} anÃ¡lises):\n"
        for i, item in enumerate(self.analysis_history, 1):
            full_summary += f"\n--- ANALISE {i} ({item['timestamp']}) ---\nPergunta: {item['query']}\nResposta: {item['response']}\n"

        conclusion_prompt = f"""
{full_summary}

Gere relatorio COMPLETO e DETALHADO com:

1. RESUMO EXECUTIVO
2. DESCOBERTAS (padrÃµes, tendÃªncias, anomalias)
3. CORRELAÃ‡Ã•ES RELEVANTES
4. QUALIDADE DOS DADOS (nulos, outliers)
5. INSIGHTS E RECOMENDAÃ‡Ã•ES
6. CONCLUSÃƒO FINAL

Seja ESPECÃFICO com NÃšMEROS das anÃ¡lises.
"""
=======
import sys
import os
import re

if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')
    sys.stderr.reconfigure(encoding='utf-8')

from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent
from langchain.agents.agent_types import AgentType
from langchain.memory import ConversationBufferMemory
from langchain.schema import OutputParserException
from src.config.settings import OPENROUTER_API_KEY, AGENT_CONFIG, OPENROUTER_BASE_URL
import pandas as pd
import streamlit as st
from dotenv import load_dotenv

load_dotenv()

import logging

# Configura logger global
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

def clean_llm_text(text: str) -> str:
    if text is None:
        return ""
    text = re.sub(r"âš ï¸.*\n?", "", str(text))
    text = re.sub(r"\[LIMIT_REACHED\].*\n?", "", text, flags=re.IGNORECASE)
    text = "\n".join(line for line in text.splitlines() if not line.strip().startswith("Thought:"))
    return text.strip()

class EDAAgent:
    def __init__(self, df: pd.DataFrame):
        """
        Inicializa agente com OpenAI e memÃ³ria completa persistente
        """
        if df is None:
            raise ValueError("DataFrame (df) nÃ£o pode ser None.")
        if not isinstance(df, pd.DataFrame):
            try:
                df = pd.DataFrame(df)
            except Exception as e:
                raise ValueError(f"NÃ£o foi possÃ­vel converter para DataFrame: {e}")

        self.df = df.copy()
                
        # HistÃ³rico estruturado de anÃ¡lises
        self.analysis_history = []
        
        # InformaÃ§Ãµes do dataset (guardadas na memÃ³ria)
        self.dataset_info = self._prepare_dataset_info()
        
        # Inicializa LLM OpenAI
        self.llm = ChatOpenAI(
            model=AGENT_CONFIG['model'],
            temperature=AGENT_CONFIG["temperature"],
            max_tokens=AGENT_CONFIG["max_tokens"],
            openai_api_key=OPENROUTER_API_KEY,
            openai_api_base=OPENROUTER_BASE_URL
            )
        
        # Cria agente pandas com memÃ³ria
        self.agent = create_pandas_dataframe_agent(
            llm=self.llm,
            df=self.df,
            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
            verbose=True,
            allow_dangerous_code=True,
            max_iterations=80,
            prefix=f"""VocÃª Ã© um Agente Especialista em EDA (Exploratory Data Analysis) e sabe gerar grÃ¡ficos muito eficientes.
                    Objetivo: analisar um ou mais arquivos CSV e gerar um relatÃ³rio tÃ©cnico de alta precisÃ£o

INFORMACOES DO DATASET:
{self.dataset_info}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
MISSÃƒO: AnÃ¡lise RÃ¡pida + Respostas Diretas + Insights de NegÃ³cio
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ¯ MODO DE OPERAÃ‡ÃƒO:

1. ANÃLISE AUTOMÃTICA (InvisÃ­vel ao usuÃ¡rio)
   â†’ Ao inicializar, vocÃª JÃ analisou o dataset em background
   â†’ EstatÃ­sticas, correlaÃ§Ãµes, outliers, padrÃµes: TUDO jÃ¡ calculado
   â†’ NÃƒO mostre essas anÃ¡lises automaticamente, apenas armazene

2. RESPOSTAS DIRETAS (Quando usuÃ¡rio pergunta)
   â†’ Pergunta simples? Resposta simples e objetiva
   â†’ Pergunta complexa? Resposta estruturada com insights
   â†’ SEMPRE cite nÃºmeros especÃ­ficos (ex: "427 outliers", "correlaÃ§Ã£o de 0.82")
   â†’ NUNCA seja vago (evite "alguns", "vÃ¡rios", "parece")

3. INSIGHTS DE NEGÃ“CIO (AlÃ©m dos nÃºmeros)
   â†’ Traduza estatÃ­sticas em impacto de negÃ³cio
   â†’ Identifique oportunidades e riscos
   â†’ Recomende aÃ§Ãµes prÃ¡ticas baseadas em dados

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š FORMATO DE RESPOSTA POR TIPO DE PERGUNTA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

PERGUNTA DIRETA (ex: "Qual a mÃ©dia de X?")
â†’ RESPOSTA: "A mÃ©dia de X Ã© 245.67. Valor acima da mediana (180.32), indicando distribuiÃ§Ã£o assimÃ©trica."

PERGUNTA EXPLORATÃ“RIA (ex: "Existem outliers?")
â†’ ESTRUTURA:
   â€¢ MÃ©todo: IQR (Q1-1.5Ã—IQR, Q3+1.5Ã—IQR)
   â€¢ Resultado: 1.847 outliers detectados (0.65% dos dados)
   â€¢ Colunas afetadas: 'amount' (1.203), 'time' (644)
   â€¢ Impacto: Outliers concentrados em transaÃ§Ãµes acima de $1.000
   â€¢ RecomendaÃ§Ã£o: Investigar manualmente transaÃ§Ãµes > $5.000

PERGUNTA COMPLEXA (ex: "Analise correlaÃ§Ãµes")
â†’ ESTRUTURA:
   âœ“ RESUMO: 3 correlaÃ§Ãµes fortes identificadas (|r|>0.7)
   âœ“ PRINCIPAIS:
     - V17 Ã— Class: r=-0.326 (negativa moderada)
     - V14 Ã— Class: r=-0.303 (indicador de fraude)
     - V2 Ã— V5: r=0.345 (colinearidade detectada)
   âœ“ INSIGHT: VariÃ¡veis V17 e V14 sÃ£o preditores-chave de fraudes
   âœ“ AÃ‡ÃƒO: Priorizar essas features em modelos de ML

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ” ANÃLISES QUE VOCÃŠ DOMINA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ ESTATÃSTICAS DESCRITIVAS
  df.describe(), mÃ©dia, mediana, moda, desvio padrÃ£o, variÃ¢ncia, quartis

âœ“ DETECÃ‡ÃƒO DE OUTLIERS
  MÃ©todo IQR: Q1-1.5Ã—IQR e Q3+1.5Ã—IQR
  Z-score: valores com |z|>3

âœ“ CORRELAÃ‡Ã•ES
  Pearson, Spearman, identificaÃ§Ã£o de multicolinearidade

âœ“ PADRÃ•ES TEMPORAIS
  TendÃªncias, sazonalidade, agrupamentos por tempo

âœ“ DISTRIBUIÃ‡Ã•ES
  Normalidade, assimetria, curtose, testes estatÃ­sticos

âœ“ QUALIDADE DE DADOS
  Nulos, duplicatas, inconsistÃªncias, tipos incorretos

âœ“ SEGMENTAÃ‡ÃƒO
  Clusters naturais, perfis de comportamento, outliers contextuais

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš¡ REGRAS DE EXECUÃ‡ÃƒO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

âœ“ SEMPRE execute cÃ³digo para validar nÃºmeros (use df disponÃ­vel)
âœ“ SEMPRE cite valores especÃ­ficos (nÃ£o arredonde demais: 2 decimais OK)
âœ“ SEMPRE explique metodologia usada em 1 linha
âœ“ SEMPRE traduza para impacto de negÃ³cio quando relevante
âœ“ MÃ¡ximo 300 palavras por resposta (exceto relatÃ³rio final)

âœ— NUNCA mostre anÃ¡lises longas automaticamente
âœ— NUNCA invente nÃºmeros sem calcular
âœ— NUNCA use termos vagos ("alguns", "bastante", "parece")
âœ— NUNCA ignore contexto de negÃ³cio

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ˆ GRÃFICOS (Apenas quando solicitado ou essencial)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Se usuÃ¡rio pedir visualizaÃ§Ã£o:
â†’ Use matplotlib/seaborn
â†’ Explique ANTES: "Gerando [tipo de grÃ¡fico] para [objetivo]"
â†’ Explique DEPOIS: Interprete o padrÃ£o visual

Tipos recomendados:
- DistribuiÃ§Ã£o â†’ Histograma
- CorrelaÃ§Ã£o â†’ Heatmap
- ComparaÃ§Ã£o â†’ Boxplot
- Temporal â†’ Line plot
- Outliers â†’ Scatter + Boxplot

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“„ RELATÃ“RIO FINAL (Apenas se solicitado explicitamente)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Quando usuÃ¡rio pedir "RELATÃ“RIO FINAL COMPLETO":

[START_REPORT]

# RELATÃ“RIO DE ANÃLISE EXPLORATÃ“RIA DE DADOS

## 1. RESUMO EXECUTIVO
- SÃ­ntese em 3-5 linhas
- Principais achados numerados

## 2. CARACTERIZAÃ‡ÃƒO DO DATASET
- DimensÃµes e tipos de dados
- Qualidade (nulos, duplicatas, inconsistÃªncias)
- EstatÃ­sticas-chave por coluna

## 3. DESCOBERTAS PRINCIPAIS
### 3.1 PadrÃµes Identificados
- Liste padrÃµes com evidÃªncias numÃ©ricas

### 3.2 CorrelaÃ§Ãµes e RelaÃ§Ãµes
- CorrelaÃ§Ãµes fortes com interpretaÃ§Ã£o
- DependÃªncias entre variÃ¡veis

### 3.3 Anomalias e Outliers
- Quantidade, localizaÃ§Ã£o, possÃ­veis causas
- Impacto nos resultados

## 4. INSIGHTS DE NEGÃ“CIO
- TraduÃ§Ã£o de cada descoberta tÃ©cnica em valor de negÃ³cio
- Oportunidades identificadas
- Riscos detectados

## 5. RECOMENDAÃ‡Ã•ES
- AÃ§Ãµes prioritÃ¡rias baseadas em dados
- PrÃ³ximos passos para investigaÃ§Ã£o
- Melhorias sugeridas

## 6. CONCLUSÃƒO
- SÃ­ntese final objetiva

[END_REPORT]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸš€ COMECE AGORA:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

VocÃª jÃ¡ analisou o dataset. Aguarde perguntas do usuÃ¡rio.
Responda de forma TÃ‰CNICA, OBJETIVA e com INSIGHTS DE NEGÃ“CIO.
"""
        )
        
        try:
            st.success(f"[OK] Agente inicializado com {AGENT_CONFIG['model']}")
        except:
            pass

# --- Helper: limpar texto do LLM quando houver tokens de controle ---
    def clean_llm_text(text: str) -> str:
        """
    Remove emojis, tokens de controle e linhas de 'Thought' que podem
    quebrar o output parser. Retorna texto limpo.
    """
        if text is None:
         return ""
    # Remover emoji âš ï¸ e qualquer ocorrÃªncia similar
        text = re.sub(r"âš ï¸.*\n?", "", text)
    # Remover o token [LIMIT_REACHED] e a linha inteira
        text = re.sub(r"\[LIMIT_REACHED\].*\n?", "", text, flags=re.IGNORECASE)
    # Remover linhas que comeÃ§am com "Thought:" (se estiverem presentes)
        text = "\n".join(line for line in text.splitlines() if not line.strip().startswith("Thought:"))
        return text.strip()

    def _prepare_dataset_info(self) -> str:
        """Prepara informaÃ§Ãµes compactas do dataset (string), semelhante ao original."""
        numeric_cols = self.df.select_dtypes(include="number").columns.tolist()
        categorical_cols = self.df.select_dtypes(include=["object", "category"]).columns.tolist()

        info = (
            f"Dataset carregado:\n"
            f"- Total de linhas: {len(self.df):,}\n"
            f"- Total de colunas: {len(self.df.columns)}\n"
            f"- Colunas numÃ©ricas ({len(numeric_cols)}): {', '.join(numeric_cols) if numeric_cols else 'Nenhuma'}\n"
            f"- Colunas categÃ³ricas ({len(categorical_cols)}): {', '.join(categorical_cols) if categorical_cols else 'Nenhuma'}\n"
            f"- MemÃ³ria: {self.df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\n"
            f"- Valores nulos (total): {int(self.df.isnull().sum().sum())}\n"
            f"- Duplicatas (linhas): {int(self.df.duplicated().sum())}\n\n"
            f"Primeiras linhas:\n{self.df.head(3).to_string()}\n"
        )
        return info

    def ask(self, query: str) -> str:
        """
        Processa pergunta com contexto completo:
        - cria enhanced_query incluindo histÃ³rico sumÃ¡rio
        - executa agent.run(...) e trata OutputParserException
        - salva histÃ³rico e persiste na memÃ³ria
        """
        try:
            context = self._get_analysis_summary()

            enhanced_query = f"""
HISTÃ“RICO:
{context}

PERGUNTA:
{query}

Responda de forma completa usando o contexto quando relevante.
"""
            # Preferimos .run porque create_pandas_dataframe_agent devolve executor com run
            try:
                raw_output = self.agent.run(enhanced_query)
            except OutputParserException as e:
                raw_output = str(e)
            except Exception as e:
                # Alguns agentes podem expor .invoke(...) â€” fallback
                try:
                    resp = self.agent.invoke({"input": enhanced_query})
                    raw_output = resp.get("output", str(resp))
                except Exception as e2:
                    raise e2

            # Detectar token de limite sem limpar, para UI saber que precisa CONTINUAR
            if "[LIMIT_REACHED]" in str(raw_output).upper() or "âš ï¸" in str(raw_output):
                result = str(raw_output)
            else:
                result = clean_llm_text(str(raw_output))

            # Salva no histÃ³rico (curto)
            self.analysis_history.append({
                "query": query,
                "response": result,
                "timestamp": pd.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")
            })

            # Salva na memÃ³ria (tratamento compatÃ­vel)
            try:
                if hasattr(self.memory, "save_context"):
                    self.memory.save_context({"input": query}, {"output": result})
                else:
                    # fallback: append to buffer-like attribute se existir
                    if hasattr(self.memory, "buffer"):
                        self.memory.buffer.append({"input": query, "output": result})
            except Exception as e:
                logger.warning("Falha ao salvar na memÃ³ria: %s", e)

            return result

        except Exception as e:
            error_msg = f"[ERRO] {str(e)}"
            logger.exception("Erro em EDAAgent.ask: %s", e)
            return error_msg

    def _get_analysis_summary(self) -> str:
        """Resumo das Ãºltimas 5 anÃ¡lises (texto curto)."""
        if not self.analysis_history:
            return "Nenhuma analise anterior."
        summary = []
        for i, item in enumerate(self.analysis_history[-5:], 1):
            snippet = item["response"][:200].replace("\n", " ")
            summary.append(f"{i}. {item['query']}: {snippet}...")
        return "\n".join(summary)

    def get_conclusions(self) -> str:
        """
        Gera conclusÃµes consolidadas baseadas no histÃ³rico.
        Chama o LLM diretamente para gerar o relatÃ³rio final.
        """
        if not self.analysis_history:
            return "Nenhuma analise realizada. FaÃ§a perguntas primeiro!"

        # ConstrÃ³i o prompt com o histÃ³rico completo (cuidado com token length)
        full_summary = f"DATASET:\n{self.dataset_info}\n\nHISTÃ“RICO COMPLETO ({len(self.analysis_history)} anÃ¡lises):\n"
        for i, item in enumerate(self.analysis_history, 1):
            full_summary += f"\n--- ANALISE {i} ({item['timestamp']}) ---\nPergunta: {item['query']}\nResposta: {item['response']}\n"

        conclusion_prompt = f"""
{full_summary}

Gere relatorio COMPLETO e DETALHADO com:

1. RESUMO EXECUTIVO
2. DESCOBERTAS (padrÃµes, tendÃªncias, anomalias)
3. CORRELAÃ‡Ã•ES RELEVANTES
4. QUALIDADE DOS DADOS (nulos, outliers)
5. INSIGHTS E RECOMENDAÃ‡Ã•ES
6. CONCLUSÃƒO FINAL

Seja ESPECÃFICO com NÃšMEROS das anÃ¡lises.
"""
>>>>>>> d4ead596466e6316ed201c1b2862c7a17a1c2125
